import pandas as pd
import numpy as np
import xgboost as xgb
import os
import sys
import json

# Ensure path is set (for when running as script)
sys.path.append(os.getcwd())

from sklearn.model_selection import train_test_split
from sbscr.core.metadata import ComplexityExtractor
from sbscr.core.lsh import LSHSignatureGenerator

def train_xgboost_scorer():
    print("ğŸš€ Starting Enterprise Scorer Training...")
    
    
    # 1. Load Data
    # Priority: Calibrated Dataset (Golden) > LMSYS Processed (Weak Labels)
    calibrated_path = "data/calibrated_dataset.json"
    weak_path = "data/lmsys/processed_lmsys_1m.csv"
    
    dataset_type = "weak"
    if os.path.exists(calibrated_path):
        print(f"ğŸ’ Found Calibrated Dataset at {calibrated_path}. Using as Golden Truth.")
        with open(calibrated_path, 'r') as f:
            raw_data = json.load(f)
        df = pd.DataFrame([
            {'prompt': item['query'], 'score_truth': item['golden_score']} 
            for item in raw_data
        ])
        dataset_type = "golden"
    elif os.path.exists(weak_path):
        df = pd.read_csv(weak_path)
    else:
        print("âŒ No data file found (checked calibrated_dataset.json and lmsys csv).")
        return
        
    print(f"ğŸ“Š Loaded {len(df)} samples ({dataset_type} mode).")
    
    # Full 1M Training Mode
    # df = df.sample(n=100000, random_state=42) # Uncomment for fast debugging
    pass
    
    extractor = ComplexityExtractor()
    lsh = LSHSignatureGenerator(num_perm=16)
    
    feature_rows = []
    labels = []
    
    print("âš™ï¸  Extracting Structural Features...")
    
    for idx, row in df.iterrows():
        try:
            prompt = str(row['prompt'])
            
            # Target: Distill the Heuristic (Pseudo-labeling)
            # Since we don't have human labels for "complexity" on LMSYS, 
            # we use our domain-expert heuristic as the 'Teacher' and train XGBoost as the 'Student'.
            target = extractor.estimate_complexity(prompt) / 10.0 # Normalize 0-1
            
            # Features
            features = extractor.extract_features(prompt)
            
            # LSH Handling
            sig = lsh.generate_signature(prompt)
            # Check if sig is MinHash object or array
            if hasattr(sig, 'hashvalues'):
                sig_vals = sig.hashvalues
            elif isinstance(sig, (list, np.ndarray)):
                sig_vals = sig
            else:
                sig_vals = []
                
            sig_mean = np.mean(sig_vals) if len(sig_vals) > 0 else 0.0

            feat_vec = [
                features.get('word_count', 0),
                features.get('unique_token_ratio', 0),
                features.get('avg_word_length', 0),
                features.get('max_line_length', 0),
                features.get('code_density', 0),        # Existing
                1 if features.get('is_code', False) else 0,
                float(sig_mean),
                # New AST Features
                features.get('ast_depth', 0),
                features.get('import_count', 0)
            ]
            
            feature_rows.append(feat_vec)
            labels.append(target)
            
            if idx > 0 and idx % 5000 == 0:
                print(f"Processed {idx} rows...")

        except Exception as e:
            print(f"âŒ Error on row {idx}: {e}")
            if idx == 0: raise e # Fail fast
            continue
            
    print(f"ğŸ“‰ Extracted {len(feature_rows)} valid training pairs.")
    
    if len(feature_rows) == 0:
        print("âŒ No valid data to train on!")
        return

    X = np.array(feature_rows)
    y = np.array(labels)
    
    print("ğŸ§  Training XGBoost...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = xgb.XGBRegressor(
        objective='reg:squarederror',
        n_estimators=100,
        learning_rate=0.1,
        max_depth=5,
        n_jobs=-1
    )
    
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)
    print(f"ğŸ“ˆ Test R^2 Score: {score:.4f}")
    
    os.makedirs("sbscr/models", exist_ok=True)
    model.save_model("sbscr/models/complexity_xgboost.json")
    print("ğŸ’¾ Model saved to sbscr/models/complexity_xgboost.json")

if __name__ == "__main__":
    train_xgboost_scorer()
